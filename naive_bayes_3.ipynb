{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive-bayes-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9HcZ7CMRMOnNKJubbaIA0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andytorrestb/AIG/blob/master/naive_bayes_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qlrDckHIoEn",
        "outputId": "0071a628-d5fd-4d44-901a-5f716c5a0b7b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnxrWCZQqRIC",
        "outputId": "721daa20-00db-43c7-8f82-7817a19d1678"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import accuracy_score as acc_score\r\n",
        "from sklearn.metrics import roc_auc_score as roc_score\r\n",
        "\r\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 60 µs, sys: 1 µs, total: 61 µs\n",
            "Wall time: 67 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn5u7-xLDQy1"
      },
      "source": [
        "The following block contains functoins for preparing the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxzSA-WBqbbw",
        "outputId": "19b35009-41f9-44fb-a23f-c3c55cc433fb"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# Replace labels for columns. Ugly but gets the job done.\r\n",
        "def replace_labels(df):\r\n",
        "  df.columns = ['age', 'workclass', 'final_weight', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\r\n",
        "             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', '<=50K']\r\n",
        "  return df\r\n",
        "\r\n",
        "# Split features according to data type. Necessary?\r\n",
        "def split_column_types(df):\r\n",
        "  num_labels = []\r\n",
        "  cat_labels = []\r\n",
        "\r\n",
        "  for feature in df.columns:\r\n",
        "    if df[feature].dtype == 'int64':\r\n",
        "      num_labels.append(feature)\r\n",
        "    else :\r\n",
        "      cat_labels.append(feature)\r\n",
        "\r\n",
        "  return num_labels, cat_labels\r\n",
        "\r\n",
        "# returns a list containing names of columns cotaining \r\n",
        "# categorical data. \r\n",
        "def make_cat_labels(df):\r\n",
        "  cat_labels = []\r\n",
        "  for feature in df.columns:\r\n",
        "    if df[feature].dtype != 'int64':\r\n",
        "      cat_labels.append(feature)\r\n",
        "\r\n",
        "  return cat_labels\r\n",
        "\r\n",
        "# Remove leading and trailing spaces from the df\r\n",
        "def strip_df(df, cat_labels):\r\n",
        "  for feature in cat_labels:\r\n",
        "    df[feature] = df[feature].str.strip()\r\n",
        "  return df\r\n",
        "\r\n",
        "# Helper function for remove_null_records\r\n",
        "def check_for_null(df, cat_labels):\r\n",
        "  missing_list = []\r\n",
        "\r\n",
        "  for feature in cat_labels:\r\n",
        "    count_list = df[feature].value_counts().index.tolist()\r\n",
        "    if count_list.count('?'):\r\n",
        "      missing_list.append(feature)\r\n",
        "  \r\n",
        "  return missing_list\r\n",
        "\r\n",
        "# Helper function for remove_null_records\r\n",
        "def insert_null_values(df, cat_labels):\r\n",
        "  missing_list = check_for_null(df, cat_labels)\r\n",
        "  for feature in missing_list:\r\n",
        "    df[feature].replace('?', np.NaN, inplace = True)\r\n",
        "  return df\r\n",
        "\r\n",
        "# Helper function for process_cat_data\r\n",
        "def remove_null_records(df, cat_labels):\r\n",
        "  return insert_null_values(df, cat_labels).dropna()\r\n",
        "\r\n",
        "# Cleans categorical data by stripping spaces\r\n",
        "# removing null records. \r\n",
        "def process_cat_data(df):\r\n",
        "  cat_labels = make_cat_labels(df)\r\n",
        "\r\n",
        "  df = strip_df(df, cat_labels)\r\n",
        "  df = remove_null_records(df, cat_labels)\r\n",
        "\r\n",
        "  return df\r\n",
        "\r\n",
        "# Changes data type of target vector from string to integer\r\n",
        "def convert_target_vector(df):\r\n",
        "  df['<=50K'].replace('<=50K', 1, inplace = True)\r\n",
        "  df['<=50K'].replace('>50K', 0, inplace = True)\r\n",
        "\r\n",
        "  return df  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20 µs, sys: 0 ns, total: 20 µs\n",
            "Wall time: 23.8 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgmnwU-VDZtX"
      },
      "source": [
        "The following block contains functions for producing distributions for model metrics. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF_Dwd3oDqhW",
        "outputId": "98d2e7bb-af9c-49fe-de90-34b3d8df61b6"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "def progress_bar(trial, no_trials):\r\n",
        "    if trial != no_trials - 1:\r\n",
        "      if trial % (no_trials / 20) == 0:\r\n",
        "        print('#', end = '')\r\n",
        "    else :\r\n",
        "      print('#')\r\n",
        "\r\n",
        "def basic_dist(df, test_pct, no_trials):\r\n",
        "  # Do that one thing. \r\n",
        "  df = df.sample(frac = 1).reset_index(drop = True)\r\n",
        "\r\n",
        "  # Instantiate the tranformer\r\n",
        "  ec = OrdinalEncoder()\r\n",
        "\r\n",
        "  # Instantiate the model\r\n",
        "  gnb = GaussianNB()\r\n",
        "\r\n",
        "  f1_dist = []\r\n",
        "\r\n",
        "  for x in range(no_trials):\r\n",
        "    X = df.drop(columns = '<=50K')\r\n",
        "    y = df['<=50K']\r\n",
        "\r\n",
        "    X = ec.fit_transform(X)\r\n",
        "\r\n",
        "    # Split into training/testing set\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\r\n",
        "  \r\n",
        "    # fit the model\r\n",
        "    gnb.fit(X_train, y_train)\r\n",
        "\r\n",
        "    # Make prediction\r\n",
        "    y_pred = gnb.predict(X_test)\r\n",
        "\r\n",
        "    # Add f1 score to list\r\n",
        "    f1_dist.append(f1_score(y_test, y_pred))\r\n",
        "\r\n",
        "    # Print small progress bar.\r\n",
        "    progress_bar(x, no_trials)\r\n",
        "    \r\n",
        "  return f1_dist\r\n",
        "\r\n",
        "# Helper function for type_error()\r\n",
        "def make_test_dict():\r\n",
        "  df = pd.DataFrame()\r\n",
        "  gnb = GaussianNB()\r\n",
        "  test_pct = 0.5\r\n",
        "  no_trials = 100\r\n",
        "\r\n",
        "  return {'df': df, 'gnb': gnb, 'test_pct': test_pct, 'no_trials': no_trials}\r\n",
        "\r\n",
        "# Simple sanity check. \r\n",
        "def type_error(model):\r\n",
        "  test = make_test_dict()\r\n",
        "\r\n",
        "  if type(model) != type(test):\r\n",
        "    return 1\r\n",
        "\r\n",
        "  if len(model) == 0:\r\n",
        "    return 1\r\n",
        "  \r\n",
        "  for feature in test.keys():\r\n",
        "    if type(test[feature]) != type(model[feature]):\r\n",
        "      return 1\r\n",
        "  \r\n",
        "def model_dist(model):\r\n",
        "\r\n",
        "  if type_error(model):\r\n",
        "    print('type error: check definition of \"model\"')\r\n",
        "    return\r\n",
        "\r\n",
        "  # list to store distributions of different metrics.\r\n",
        "  f1_dist = []\r\n",
        "  acc_dist = []\r\n",
        "  roc_dist = []\r\n",
        "\r\n",
        "  # Do that one thing. TODO: look this up\r\n",
        "  model['df'] = model['df'].sample(frac = 1).reset_index(drop = True)\r\n",
        "\r\n",
        "  # Instantiate the tranformer\r\n",
        "  ec = OrdinalEncoder()\r\n",
        "  \r\n",
        "  for x in range(model['no_trials']):\r\n",
        "    X = model[\"df\"].drop(columns = '<=50K')\r\n",
        "    y = model[\"df\"][\"<=50K\"]\r\n",
        "\r\n",
        "    X = ec.fit_transform(X)\r\n",
        "\r\n",
        "    # Split into training/testing set\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\r\n",
        "  \r\n",
        "    # fit the model\r\n",
        "    gnb.fit(X_train, y_train)\r\n",
        "\r\n",
        "    # Make prediction\r\n",
        "    y_pred = gnb.predict(X_test)\r\n",
        "\r\n",
        "    # Update individual metrics\r\n",
        "    f1_dist.append(f1_score(y_test, y_pred))\r\n",
        "    acc_dist.append(acc_score(y_test, y_pred))\r\n",
        "    roc_dist.append(roc_score(y_test, y_pred))\r\n",
        "\r\n",
        "    # Print small progress bar.\r\n",
        "    progress_bar(x, model['no_trials'])\r\n",
        "  \r\n",
        "  print('Success')\r\n",
        "  return {'f1': f1_dist, 'acc': acc_dist, 'roc': roc_dist}\r\n",
        "  \r\n",
        "\r\n",
        "def metric_dist(df, test_pct, no_trials): \r\n",
        "\r\n",
        "  # list to store distributions of different metrics.\r\n",
        "  f1_dist = []\r\n",
        "  acc_dist = []\r\n",
        "  roc_dist = []\r\n",
        "\r\n",
        "  # Do that one thing. TODO: look this up\r\n",
        "  df = df.sample(frac = 1).reset_index(drop = True)\r\n",
        "\r\n",
        "  # Instantiate the tranformer\r\n",
        "  ec = OrdinalEncoder()\r\n",
        "\r\n",
        "  # Instantiate the model\r\n",
        "  gnb = GaussianNB()\r\n",
        "\r\n",
        "  for x in range(no_trials):\r\n",
        "    X = df.drop(columns = '<=50K')\r\n",
        "    y = df['<=50K']\r\n",
        "\r\n",
        "    X = ec.fit_transform(X)\r\n",
        "\r\n",
        "    # Split into training/testing set\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\r\n",
        "  \r\n",
        "    # fit the model\r\n",
        "    gnb.fit(X_train, y_train)\r\n",
        "\r\n",
        "    # Make prediction\r\n",
        "    y_pred = gnb.predict(X_test)\r\n",
        "\r\n",
        "    # Update individual metrics\r\n",
        "    f1_dist.append(f1_score(y_test, y_pred))\r\n",
        "    acc_dist.append(acc_score(y_test, y_pred))\r\n",
        "    roc_dist.append(roc_score(y_test, y_pred))\r\n",
        "\r\n",
        "    # Print small progress bar.\r\n",
        "    progress_bar(x, no_trials)\r\n",
        "  \r\n",
        "  metrics = {'f1': f1_dist, 'acc': acc_dist, 'roc': roc_dist}\r\n",
        "  return metrics\r\n",
        "\r\n",
        "# TODO: write, and package set of parameters into a dictionary. \r\n",
        "# can probably replace basic_dict()\r\n",
        "# def tuned_dist(df, test_pct, no_trials, gnb):\r\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14 µs, sys: 0 ns, total: 14 µs\n",
            "Wall time: 18.6 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz8ksE6drLlh",
        "outputId": "4949c4b4-690d-4b0e-d299-eb0d43b4029e"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# Load data. \r\n",
        "path = '/content/drive/My Drive/adult.csv'\r\n",
        "train = replace_labels(pd.read_csv(path))\r\n",
        "\r\n",
        "train = process_cat_data(train)\r\n",
        "train = convert_target_vector(train)\r\n",
        "\r\n",
        "# sns.histplot(x = basic_dist(train, 0.1, 10))\r\n",
        "# metrics = metric_dist(train, 0.1, 10)\r\n",
        "\r\n",
        "gnb = GaussianNB()\r\n",
        "test_pct = 0.5\r\n",
        "no_trials = 100\r\n",
        "\r\n",
        "model = {'df': train, 'gnb': gnb, 'test_pct': test_pct, 'no_trials': no_trials}\r\n",
        "\r\n",
        "metrics = model_dist(model)\r\n",
        "\r\n",
        "print(type(metrics))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#####################\n",
            "Success\n",
            "<class 'dict'>\n",
            "CPU times: user 21.4 s, sys: 126 ms, total: 21.5 s\n",
            "Wall time: 21.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8L9paqGTLR1"
      },
      "source": [
        "Basic model at different test/train splits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_AdCyfUTJsF",
        "outputId": "0495c9ea-34a6-4b8f-a6f6-8a86faa5537b"
      },
      "source": [
        "type(metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1obh8uhTX3b"
      },
      "source": [
        "Run hyperparamter search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZUy-6XzTalF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuN3FrOmTb0e",
        "outputId": "295250e3-0fc8-4161-86bc-a65e4ec3c0a0"
      },
      "source": [
        "t = {}\r\n",
        "type(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}